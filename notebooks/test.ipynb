{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'1.13.0'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2419382481.py, line 49)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Input \u001B[1;32mIn [31]\u001B[1;36m\u001B[0m\n\u001B[1;33m    ConvBlock(256, 512, sample=)\u001B[0m\n\u001B[1;37m                               ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "def init_weights(module):\n",
    "    if type(module) == nn.Conv2d:\n",
    "        nn.init.xavier_normal(module.weight)\n",
    "\n",
    "def crop(image: torch.Tensor, new_shape: int):\n",
    "    if image.shape[-1] == new_shape:\n",
    "        return image\n",
    "\n",
    "    pad = image.shape[-1] - new_shape\n",
    "\n",
    "    if pad % 2 == 0:\n",
    "        pad = pad // 2\n",
    "        return image[..., pad:-pad, pad:-pad]\n",
    "\n",
    "    return image[..., :-pad, :-pad]\n",
    "\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels: int, out_channels: int, padding: str = \"valid\", sample: str = None):\n",
    "        super().__init__()\n",
    "\n",
    "        module_list = [\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=(3, 3), padding=padding),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=(3, 3), padding=padding),\n",
    "            nn.ReLU(),\n",
    "        ]\n",
    "\n",
    "        if sample == \"down\":\n",
    "            module_list.insert(0, nn.MaxPool2d(kernel_size=(2, 2), stride=2))\n",
    "        elif sample == \"up\":\n",
    "            module_list.append(nn.ConvTranspose2d(in_channels=out_channels, out_channels=(out_channels // 2), kernel_size=(2, 2), stride=2))\n",
    "\n",
    "        self.block = nn.Sequential(*module_list)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block.forward(x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ImageEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.compression_block = nn.ModuleList([\n",
    "            ConvBlock(3, 64),\n",
    "            ConvBlock(64, 128, sample=\"down\"),\n",
    "            ConvBlock(128, 256, sample=\"down\"),\n",
    "            ConvBlock(256, 512, sample=\"down\"),\n",
    "            ConvBlock(512, 1024, sample=\"down\")\n",
    "        ])\n",
    "\n",
    "        self.compression_block.apply(init_weights)\n",
    "\n",
    "    def forward(self, image):\n",
    "        outputs = []\n",
    "        for block in self.compression_block:\n",
    "            x = block.forward(x)\n",
    "            outputs.append(x.clone())\n",
    "\n",
    "        return outputs[:-1], outputs[-1]\n",
    "\n",
    "class ImageDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.decoder_sequence = nn.Sequential()\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "class CompressionBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, padding='valid'):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            nn.Conv2d(out_channels, out_channels, 3),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2)\n",
    "        )\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "model = ImageEncoder()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "test = torch.randn(1, 3, 1200, 800)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 3, 1200, 800])"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 36, 198, 131])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(test).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
